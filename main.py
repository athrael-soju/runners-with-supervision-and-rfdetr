# -*- coding: utf-8 -*-
"""how-to-track-objects-with-sort-tracker.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VT_FYIe3kborhWrfKKBqqfR0EjQeQNiO

[![Roboflow Notebooks](https://media.roboflow.com/notebooks/template/bannertest2-2.png?ik-sdk-version=javascript-1.4.3&updatedAt=1672932710194)](https://github.com/roboflow/notebooks)

# How to Track Objects with SORT Tracker

SORT (Simple Online and Realtime Tracking) is a lean, tracking-by-detection method that combines a Kalman filter for motion prediction with the Hungarian algorithm for data association. It uses object detections—commonly from a high-performing CNN-based detector—as its input, updating each tracked object's bounding box based on linear velocity estimates. Because SORT relies on minimal appearance modeling (only bounding box geometry is used), it is extremely fast and can run comfortably at hundreds of frames per second. This speed and simplicity make it well suited for real-time applications in robotics or surveillance, where rapid, approximate solutions are essential. However, its reliance on frame-to-frame matching makes SORT susceptible to ID switches and less robust during long occlusions, since there is no built-in re-identification module.

## Environment setup

### Check GPU availability

Let's make sure that we have access to GPU. We can use `nvidia-smi` command to do that. In case of any problems navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator`, set it to `T4 GPU`, and then click `Save`.
"""

# !nvidia-smi

"""### Install dependencies"""

# !pip install -U -q git+https://github.com/roboflow/rf-detr.git
# !pip install -U -q git+https://github.com/roboflow/trackers.git
# !pip install -U -q git+https://github.com/roboflow/supervision.git

"""### Download example data"""

# !wget -q https://storage.googleapis.com/com-roboflow-marketing/trackers/assets/traffic_video_1.mp4

SOURCE_VIDEO_PATH = "./input/bikes-1280x720-1.mp4"

"""## Imports"""

import supervision as sv
from rfdetr import RFDETRBase
from rfdetr.util.coco_classes import COCO_CLASSES
from trackers import DeepSORTFeatureExtractor, DeepSORTTracker
import numpy as np
import pandas as pd
import os
import matplotlib.pyplot as plt
from collections import defaultdict, Counter
# Import the ReportGenerator
from report_generator import ReportGenerator, generate_heatmap

"""## Track objects

### Initiate detector and tracker
"""

model = RFDETRBase(device="mps")

# Set confidence threshold
CONFIDENCE_THRESHOLD = 0.5

feature_extractor = DeepSORTFeatureExtractor.from_timm(
    model_name="mobilenetv4_conv_small.e1200_r224_in1k"
)
tracker = DeepSORTTracker(feature_extractor=feature_extractor)

"""### Configure annotators"""

color = sv.ColorPalette.from_hex([
    "#ffff00", "#ff9b00", "#ff8080", "#ff66b2", "#ff66ff", "#b266ff",
    "#9999ff", "#3399ff", "#66ffff", "#33ff99", "#66ff66", "#99ff00"
])

box_annotator = sv.BoxAnnotator(
    color=color,
    color_lookup=sv.ColorLookup.TRACK)

label_annotator = sv.LabelAnnotator(
    color=color,
    color_lookup=sv.ColorLookup.TRACK,
    text_color=sv.Color.BLACK,
    text_scale=1.0)

"""### Run detection + tracking"""

def callback(frame, index):
    # Obtain bounding box predictions from RF-DETR
    detections = model.predict(frame, threshold=CONFIDENCE_THRESHOLD)

    # Update tracker with new detections and retrieve updated IDs
    detections = tracker.update(detections, frame)

    # Filter out detections with IDs of -1 (fresh tracks not yet confirmed)
    detections = detections[detections.tracker_id != -1]

    # Add COCO class names to labels
    labels = [f"#{t_id} | {COCO_CLASSES[class_id]}" 
              for t_id, class_id in zip(detections.tracker_id, detections.class_id)]

    # Update report data if the report generator exists
    if hasattr(callback, 'report_generator') and callback.report_generator:
        callback.report_generator.update(detections, index)

    # Store detections for heatmap generation if needed
    if hasattr(callback, 'detections_history') and callback.detections_history is not None:
        callback.detections_history.append(detections)

    annotated_image = frame.copy()
    annotated_image = box_annotator.annotate(annotated_image, detections)
    annotated_image = label_annotator.annotate(annotated_image, detections, labels)

    return annotated_image

TARGET_VIDEO_PATH = "./output/bikes-1280x720-1-result.mp4"

def process_video_with_report(generate_report=False, generate_heatmap_output=False, report_dir="./report"):
    # Initialize report generator if needed
    if generate_report:
        callback.report_generator = ReportGenerator(COCO_CLASSES)
    else:
        callback.report_generator = None
    
    # Initialize detections history for heatmap if needed
    if generate_heatmap_output:
        callback.detections_history = []
    else:
        callback.detections_history = None
    
    # Process the video
    frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)
    # Get the first frame to determine dimensions for heatmap
    for first_frame in frame_generator:
        frame_shape = first_frame.shape[:2]  # (height, width)
        break
    
    # Process video
    sv.process_video(
        source_path=SOURCE_VIDEO_PATH,
        target_path=TARGET_VIDEO_PATH,
        callback=callback,
        max_frames=300,
        show_progress=True,
    )
    
    # Generate report if requested
    if generate_report and callback.report_generator:
        report_path = callback.report_generator.generate_report(output_dir=report_dir)
        print(f"Report generated: {report_path}")
    
    # Generate heatmap if requested
    if generate_heatmap_output and callback.detections_history:
        heatmap_path = generate_heatmap(
            callback.detections_history, 
            frame_shape, 
            output_dir=report_dir
        )
        print(f"Heatmap generated: {heatmap_path}")

# Run video processing with report generation enabled
process_video_with_report(generate_report=True)

# Example of how to run with different options:
# process_video_with_report(generate_report=True, generate_heatmap_output=True, report_dir="./custom_report_directory")