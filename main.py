# -*- coding: utf-8 -*-
"""how-to-track-objects-with-sort-tracker.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VT_FYIe3kborhWrfKKBqqfR0EjQeQNiO

[![Roboflow Notebooks](https://media.roboflow.com/notebooks/template/bannertest2-2.png?ik-sdk-version=javascript-1.4.3&updatedAt=1672932710194)](https://github.com/roboflow/notebooks)

# How to Track Objects with SORT Tracker

SORT (Simple Online and Realtime Tracking) is a lean, tracking-by-detection method that combines a Kalman filter for motion prediction with the Hungarian algorithm for data association. It uses object detections—commonly from a high-performing CNN-based detector—as its input, updating each tracked object's bounding box based on linear velocity estimates. Because SORT relies on minimal appearance modeling (only bounding box geometry is used), it is extremely fast and can run comfortably at hundreds of frames per second. This speed and simplicity make it well suited for real-time applications in robotics or surveillance, where rapid, approximate solutions are essential. However, its reliance on frame-to-frame matching makes SORT susceptible to ID switches and less robust during long occlusions, since there is no built-in re-identification module.

## Environment setup

### Check GPU availability

Let's make sure that we have access to GPU. We can use `nvidia-smi` command to do that. In case of any problems navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator`, set it to `T4 GPU`, and then click `Save`.
"""

# !nvidia-smi

"""### Install dependencies"""

# !pip install -U -q git+https://github.com/roboflow/rf-detr.git
# !pip install -U -q git+https://github.com/roboflow/trackers.git
# !pip install -U -q git+https://github.com/roboflow/supervision.git

"""### Download example data"""

# !wget -q https://storage.googleapis.com/com-roboflow-marketing/trackers/assets/traffic_video_1.mp4

SOURCE_VIDEO_PATH = "./input/ok.mp4"

"""## Imports"""

import supervision as sv
from rfdetr import RFDETRBase
from rfdetr.util.coco_classes import COCO_CLASSES
from trackers import DeepSORTFeatureExtractor, DeepSORTTracker
import numpy as np
import os
import argparse
from report_generator import TrackingReporter, print_tracking_summary

try:
    from visualization import generate_visualizations

    visualization_available = True
except ImportError:
    visualization_available = False
    print(
        "Visualization module not available. Install matplotlib, seaborn, and opencv-python to enable."
    )

"""## Track objects

### Initiate detector and tracker
"""

model = RFDETRBase(device="mps")

# Set confidence threshold
CONFIDENCE_THRESHOLD = 0.5

feature_extractor = DeepSORTFeatureExtractor.from_timm(
    model_name="mobilenetv4_conv_small.e1200_r224_in1k"
)
tracker = DeepSORTTracker(feature_extractor=feature_extractor)

"""### Configure annotators"""

color = sv.ColorPalette.from_hex(
    [
        "#ffff00",
        "#ff9b00",
        "#ff8080",
        "#ff66b2",
        "#ff66ff",
        "#b266ff",
        "#9999ff",
        "#3399ff",
        "#66ffff",
        "#33ff99",
        "#66ff66",
        "#99ff00",
    ]
)

box_annotator = sv.BoxAnnotator(color=color, color_lookup=sv.ColorLookup.TRACK)

label_annotator = sv.LabelAnnotator(
    color=color,
    color_lookup=sv.ColorLookup.TRACK,
    text_color=sv.Color.BLACK,
    text_scale=1.0,
)

"""### Run detection + tracking"""


def callback(frame, index):
    # Obtain bounding box predictions from RF-DETR
    detections = model.predict(frame, threshold=CONFIDENCE_THRESHOLD)

    # Update tracker with new detections and retrieve updated IDs
    detections = tracker.update(detections, frame)

    # Filter out detections with IDs of -1 (fresh tracks not yet confirmed)
    detections = detections[detections.tracker_id != -1]

    # Update tracking reporter if enabled
    if "reporter" in globals() and reporter is not None:
        reporter.update(detections, index)

    # Add COCO class names to labels
    labels = [
        f"#{t_id} | {COCO_CLASSES[class_id]}"
        for t_id, class_id in zip(detections.tracker_id, detections.class_id)
    ]

    annotated_image = frame.copy()
    annotated_image = box_annotator.annotate(annotated_image, detections)
    annotated_image = label_annotator.annotate(annotated_image, detections, labels)

    return annotated_image


TARGET_VIDEO_PATH = "./output/" + SOURCE_VIDEO_PATH.split("/")[-1] + ".mp4"


def process_video():
    # Process the video
    sv.process_video(
        source_path=SOURCE_VIDEO_PATH,
        target_path=TARGET_VIDEO_PATH,
        callback=callback,
        max_frames=1000,
        show_progress=True,
    )


if __name__ == "__main__":
    # Parse command line arguments
    parser = argparse.ArgumentParser(description="Object tracking with SORT")
    parser.add_argument(
        "--report", action="store_true", help="Generate tracking reports"
    )
    parser.add_argument(
        "--visualize",
        action="store_true",
        help="Generate visualizations for tracking data",
    )
    args = parser.parse_args()

    # Initialize reporter if reports or visualizations are requested
    reporter = None
    if args.report or args.visualize:
        reporter = TrackingReporter(SOURCE_VIDEO_PATH)

    # Process the video
    process_video()

    # Generate reports if requested
    if args.report:
        reporter.generate_reports()
        print_tracking_summary(reporter)

    # Generate visualizations if requested
    if args.visualize:
        if not visualization_available:
            print("ERROR: Visualization module not available.")
            print(
                "Please install required dependencies: pip install matplotlib seaborn pandas"
            )
        else:
            try:
                # If we've just generated reports, read from the reports folder
                viz_dir = generate_visualizations("reports/report.json")
                print(f"Visualizations have been generated in {viz_dir}")
            except Exception as e:
                print(f"Error generating visualizations: {e}")
