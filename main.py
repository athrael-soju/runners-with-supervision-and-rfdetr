# -*- coding: utf-8 -*-
"""how-to-track-objects-with-sort-tracker.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VT_FYIe3kborhWrfKKBqqfR0EjQeQNiO

[![Roboflow Notebooks](https://media.roboflow.com/notebooks/template/bannertest2-2.png?ik-sdk-version=javascript-1.4.3&updatedAt=1672932710194)](https://github.com/roboflow/notebooks)

# How to Track Objects with SORT Tracker

SORT (Simple Online and Realtime Tracking) is a lean, tracking-by-detection method that combines a Kalman filter for motion prediction with the Hungarian algorithm for data association. It uses object detections—commonly from a high-performing CNN-based detector—as its input, updating each tracked object's bounding box based on linear velocity estimates. Because SORT relies on minimal appearance modeling (only bounding box geometry is used), it is extremely fast and can run comfortably at hundreds of frames per second. This speed and simplicity make it well suited for real-time applications in robotics or surveillance, where rapid, approximate solutions are essential. However, its reliance on frame-to-frame matching makes SORT susceptible to ID switches and less robust during long occlusions, since there is no built-in re-identification module.

## Environment setup

### Check GPU availability

Let's make sure that we have access to GPU. We can use `nvidia-smi` command to do that. In case of any problems navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator`, set it to `T4 GPU`, and then click `Save`.
"""

# !nvidia-smi

"""### Install dependencies"""

# !pip install -U -q git+https://github.com/roboflow/rf-detr.git
# !pip install -U -q git+https://github.com/roboflow/trackers.git
# !pip install -U -q git+https://github.com/roboflow/supervision.git

"""### Download example data"""

# !wget -q https://storage.googleapis.com/com-roboflow-marketing/trackers/assets/traffic_video_1.mp4

SOURCE_VIDEO_PATH = "./input/ok.mp4"

"""## Imports"""

import supervision as sv
from rfdetr import RFDETRBase
from rfdetr.util.coco_classes import COCO_CLASSES
from trackers import DeepSORTFeatureExtractor, DeepSORTTracker
import numpy as np
import os

"""## Track objects

### Initiate detector and tracker
"""

model = RFDETRBase(device="mps")

# Set confidence threshold
CONFIDENCE_THRESHOLD = 0.5

feature_extractor = DeepSORTFeatureExtractor.from_timm(
    model_name="mobilenetv4_conv_small.e1200_r224_in1k"
)
tracker = DeepSORTTracker(feature_extractor=feature_extractor)

"""### Configure annotators"""

color = sv.ColorPalette.from_hex([
    "#ffff00", "#ff9b00", "#ff8080", "#ff66b2", "#ff66ff", "#b266ff",
    "#9999ff", "#3399ff", "#66ffff", "#33ff99", "#66ff66", "#99ff00"
])

box_annotator = sv.BoxAnnotator(
    color=color,
    color_lookup=sv.ColorLookup.TRACK)

label_annotator = sv.LabelAnnotator(
    color=color,
    color_lookup=sv.ColorLookup.TRACK,
    text_color=sv.Color.BLACK,
    text_scale=1.0)

"""### Run detection + tracking"""

def callback(frame, index):
    # Obtain bounding box predictions from RF-DETR
    detections = model.predict(frame, threshold=CONFIDENCE_THRESHOLD)

    # Update tracker with new detections and retrieve updated IDs
    detections = tracker.update(detections, frame)

    # Filter out detections with IDs of -1 (fresh tracks not yet confirmed)
    detections = detections[detections.tracker_id != -1]

    # Add COCO class names to labels
    labels = [f"#{t_id} | {COCO_CLASSES[class_id]}" 
              for t_id, class_id in zip(detections.tracker_id, detections.class_id)]

    annotated_image = frame.copy()
    annotated_image = box_annotator.annotate(annotated_image, detections)
    annotated_image = label_annotator.annotate(annotated_image, detections, labels)

    return annotated_image

TARGET_VIDEO_PATH = "./output/"+SOURCE_VIDEO_PATH.split("/")[-1]+".mp4"

def process_video():
    # Process the video
    sv.process_video(
        source_path=SOURCE_VIDEO_PATH,
        target_path=TARGET_VIDEO_PATH,
        callback=callback,
        max_frames=1000,
        show_progress=True,
    )

# Run video processing
process_video()