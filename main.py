# -*- coding: utf-8 -*-
"""how-to-track-objects-with-sort-tracker.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VT_FYIe3kborhWrfKKBqqfR0EjQeQNiO

[![Roboflow Notebooks](https://media.roboflow.com/notebooks/template/bannertest2-2.png?ik-sdk-version=javascript-1.4.3&updatedAt=1672932710194)](https://github.com/roboflow/notebooks)

# How to Track Objects with SORT Tracker

SORT (Simple Online and Realtime Tracking) is a lean, tracking-by-detection method that combines a Kalman filter for motion prediction with the Hungarian algorithm for data association. It uses object detections—commonly from a high-performing CNN-based detector—as its input, updating each tracked object's bounding box based on linear velocity estimates. Because SORT relies on minimal appearance modeling (only bounding box geometry is used), it is extremely fast and can run comfortably at hundreds of frames per second. This speed and simplicity make it well suited for real-time applications in robotics or surveillance, where rapid, approximate solutions are essential. However, its reliance on frame-to-frame matching makes SORT susceptible to ID switches and less robust during long occlusions, since there is no built-in re-identification module.

## Environment setup

### Check GPU availability

Let's make sure that we have access to GPU. We can use `nvidia-smi` command to do that. In case of any problems navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator`, set it to `T4 GPU`, and then click `Save`.
"""

# !nvidia-smi

"""### Install dependencies"""

# !pip install -U -q git+https://github.com/roboflow/rf-detr.git
# !pip install -U -q git+https://github.com/roboflow/trackers.git
# !pip install -U -q git+https://github.com/roboflow/supervision.git

"""### Download example data"""

# !wget -q https://storage.googleapis.com/com-roboflow-marketing/trackers/assets/traffic_video_1.mp4

SOURCE_VIDEO_PATH = "./input/skater_boys.mp4"

"""## Imports"""

from rfdetr import RFDETRBase
from rfdetr.util.coco_classes import COCO_CLASSES
from trackers import DeepSORTFeatureExtractor, DeepSORTTracker
import argparse
from report_generator import TrackingReporter, print_tracking_summary
from processor import VideoProcessor

try:
    from visualization_generator import generate_visualizations

    visualization_available = True
except ImportError:
    visualization_available = False
    print(
        "Visualization module not available. Install matplotlib, seaborn, and opencv-python to enable."
    )

if __name__ == "__main__":
    # Parse command line arguments
    parser = argparse.ArgumentParser(description="Object tracking with SORT")
    parser.add_argument(
        "--report", action="store_true", help="Generate tracking reports"
    )
    parser.add_argument(
        "--visualize",
        action="store_true",
        help="Generate visualizations for tracking data",
    )
    parser.add_argument(
        "--seconds", type=float, help="Number of seconds to process from the video"
    )
    parser.add_argument("--fps", type=float, help="Output FPS for the processed video")
    parser.add_argument(
        "--start_frame", type=int, help="Start frame for processing the video"
    )
    parser.add_argument(
        "--low_fps", action="store_true", help="Optimize tracking for low FPS videos"
    )
    args = parser.parse_args()

    # Initialize detector
    model = RFDETRBase(device="cuda")
    model.classes_dict = COCO_CLASSES

    # Initialize feature extractor for DeepSORT
    feature_extractor = DeepSORTFeatureExtractor.from_timm(
        model_name="convnext_base.fb_in1k"
    )

    # Initialize tracker with appropriate settings
    if args.low_fps:
        print("Using low FPS optimized tracking settings")
        tracker = DeepSORTTracker(
            feature_extractor=feature_extractor,
            lost_track_buffer=60,  # Increase frames to buffer when a track is lost
            frame_rate=1,  # Set a low frame rate expectation
            track_activation_threshold=0.5,  # Lower threshold to activate tracks
            minimum_consecutive_frames=2,  # Fewer frames to confirm a track
            minimum_iou_threshold=0.3,  # Lower IOU requirement for matching
            appearance_threshold=0.8,  # Higher tolerance for appearance differences
            appearance_weight=0.75,  # Prioritize appearance over motion
            distance_metric="cosine",  # Use cosine distance for appearance
        )
    else:
        # Default tracker settings for normal FPS
        tracker = DeepSORTTracker(feature_extractor=feature_extractor)

    # Initialize reporter if reports or visualizations are requested
    reporter = None
    if args.report or args.visualize:
        reporter = TrackingReporter(SOURCE_VIDEO_PATH)

    # Initialize video processor
    processor = VideoProcessor(
        source_path=SOURCE_VIDEO_PATH,
        model=model,
        tracker=tracker,
        confidence_threshold=0.5,
        reporter=reporter,
    )

    # Process the video
    processor.process_video(
        seconds=args.seconds, output_fps=args.fps, start_frame=args.start_frame
    )

    # Generate reports if requested
    if args.report:
        reporter.generate_reports()
        print_tracking_summary(reporter)

    # Generate visualizations if requested
    if args.visualize:
        if not visualization_available:
            print("ERROR: Visualization module not available.")
            print(
                "Please install required dependencies: pip install matplotlib seaborn pandas"
            )
        else:
            try:
                # If we've just generated reports, read from the reports folder
                generate_visualizations("reports/report.json")
            except Exception as e:
                print(f"Error generating visualizations: {e}")
